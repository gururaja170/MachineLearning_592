{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sp22HW4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOhisftXb/Dub0IcId+6sbp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/MAT592/blob/main/homework/HW4/Sp22HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Homework 4\n",
        "## Homework guideline\n",
        "- The deadline is Apr 26th 10:30am. Submission after the deadline will not be graded. \n",
        "\n",
        "- Submit your work(your reasoning and your code) as a SINGLE .ipynb document. Please rename the document as _HW1_YOURNAME.ipynb_ (for example, _HW1_FELIX.ipynb_). You are responsible for checking that you have correctly submitted the correct document. If your code cannot run, you may receive NO point. \n",
        "\n",
        "- Please justify all short answers with a brief explanation.\n",
        "\n",
        "- You only use the Python packages included in the following cell. You are not allowed to use other advanced package or modules unless you are permitted to. \n",
        "\n",
        "- In your final submission include the plots produced by the unedited code as presented below, as well as any additional plots produced after editing the code during the course of a problem. You may find it necessary to copy/paste relevant code into additional cells to accomplish this.\n",
        "\n",
        "- Feel free to use the lecture notes and other resources but work on your own!"
      ],
      "metadata": {
        "id": "yzbdFr4gF6g0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ndkcp27gFz2K"
      },
      "outputs": [],
      "source": [
        "%pylab inline \n",
        "import numpy.linalg as LA\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "\n",
        "## Set some default values of the the matplotlib plots\n",
        "plt.rcParams['figure.figsize'] = (8.0, 8.0)  # Set default plot's sizes\n",
        "plt.rcParams['axes.grid'] = True  # Show grid by default in figures"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description\n",
        "In this assignment, we will use the K-NN and LDA methods for face recognition. Our task here is to be able to predict the correct label (name of the person) given an image of his face.\n",
        "\n",
        "We will use PCA for generating features for our classifiers.\n",
        "\n",
        "For this task, we will use a dataset called [Labeled Faces in the Wild](http://vis-www.cs.umass.edu/lfw/), which contains 13233 images of faces which belong to  5749 people. Each image in the dataset is labeled with a number corresponding to a person's name. All the images in the dataset are cropped and resized to the same image size.\n",
        "\n",
        "To load the data, we will use the scikit-learn's function [sklearn.datasets.fetch_lfw_people](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_lfw_people.html). To make our life a bit easier we will only use faces of people which appear in the dataset more than 100 times."
      ],
      "metadata": {
        "id": "5gQkc_MYHCBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "dataset = fetch_lfw_people(min_faces_per_person=100)\n",
        "\n",
        "X = dataset.images\n",
        "y = dataset.target\n",
        "label_to_name_mapping = dataset.target_names\n",
        "image_shape = x[0].shape\n",
        "\n",
        "print('Number of images in the dataset: {}'.format(len(x)))\n",
        "print('Number of different persons in the dataset: {}'.format(len(np.unique(y))))\n",
        "print('Each images size is: {}'.format(image_shape))\n",
        "\n",
        "_, images_per_class = np.unique(y, return_counts=True)\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(label_to_name_mapping, images_per_class)\n",
        "ax.set_xticklabels(label_to_name_mapping, rotation=-90);\n",
        "ax.set_title('Images per person')\n",
        "ax.set_ylabel('Number of images')\n",
        "\n",
        "\n",
        "# plots the first 20 images in the dataset. \n",
        "fig, ax_array = plt.subplots(4, 5)\n",
        "for i, ax in enumerate(ax_array.flat):\n",
        "    ax.imshow(x[i], cmap='gray')\n",
        "    ax.set_ylabel(label_to_name_mapping[y[i]])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks([])"
      ],
      "metadata": {
        "id": "2-5KUna4H6ls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# split the data into 80% training set and 20% testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "au6rVEsVIXEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Q1: PCA (40pt)\n",
        "Instead of working directly with the pixels as our input, we would like to select a smaller number of features to use as an input to our classifier.\n",
        "\n",
        "We will use PCA to represent a given image using a smaller number of variables. \n",
        "\n",
        "We can also think of this task as trying to compress the image representation.\n",
        "\n",
        "Currently, each image is represented using 2914 numbers (47 x 62 pixels). Let us try to reduce this number using PCA. This, of course, will come at the cost of not being able to reconstruct the image exactly, but only approximately.\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.1: Prepare data\n",
        "In order to use PCA on the images need to store each image as a vector. We will reshape each image to be a 1d vector of size 2914 x 1.\n"
      ],
      "metadata": {
        "id": "0H1sVJdYKE9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q1.1 \n",
        "# your code starts here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "eO9nfLY0KzzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.2 Eigenface\n",
        "Apply the principle component analysis on the dataset and **plot the singular values**. Each eigenvector has the same dimensionality as the original images, and thus can itself be seen as an image. These eigenvectors (after reshaping into  $47\\times 62$ pixels) are therefore called **Eigenfaces**. Please plot the first nine eigenfaces which corresponding the top nine singular values. "
      ],
      "metadata": {
        "id": "g8R42btQLK95"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q1.2 \n",
        "# your code starts here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "0n3z9Xm3LeBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "### Q1.3 Reconstruction images \n",
        "Use one random chosen image as the test, please plot the reconstructed image and error as a function of the number of principle components. You could tell it is reasonable to choose 300 principle components here. \n",
        "\n",
        "Then please use top 300 principle components (Eigenfaces) to reconstruct all images. This compress the whole dataset at once. Pick any image after the compression and visualize it. Show the effect of PCA by comparing the original image and the PCA images side by side using subplot. "
      ],
      "metadata": {
        "id": "HaWxSPxKLuH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q1.3\n",
        "# your code starts here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "13_zSKT7MPZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Now each image is 300 dimensional instead of 2914 dimensional, without losing lots of information. You can apply all sorts of ML algorithm (classification and clustering) on this 300 dimensional array. This will significantly speed up your learning.\n",
        "# Q2: 1-NN classification (30pt)\n",
        "\n",
        "Try to classify the images in the testing set using 1-nearest neighbor (1-NN) of the training set. Please calculate the misclassification rate. \n",
        "\n"
      ],
      "metadata": {
        "id": "t2u5Z5eBMU09"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q2\n",
        "# your code starts here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6JqaifXuX8k8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Q3: Linear discrimination analysis (LDA) (30pt)\n",
        "### Q3.1 Learning\n",
        "Calculate the model's parameters using MLE.\n",
        "Reminder, LDA's model parameters are:\n",
        "- The mean values for each class\n",
        "- The covariance matrix for all classes.\n",
        "- The prior distribution of each class."
      ],
      "metadata": {
        "id": "yNjea3b8Zuiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q3.1\n",
        "# your code starts here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8-cM4JQCbEWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3.2 Classication\n",
        "Use the estimated parameters to build our classifier. Please calculate the misclassification rate. Could you plot serveral pictures that LDA misclassified. "
      ],
      "metadata": {
        "id": "AdOjrx14bOMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title  Q3.2\n",
        "# your code starts here"
      ],
      "metadata": {
        "cellView": "form",
        "id": "A3PYtz8ibt-t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}