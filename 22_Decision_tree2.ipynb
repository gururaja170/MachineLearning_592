{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "22_Decision_tree2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNd5tsZ7AVVKCTvzcb3ge8s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/MAT592/blob/main/22_Decision_tree2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NWM8_rbaOpb"
      },
      "source": [
        "\n",
        "Part of the notebook is based on https://medium.com/@joachimvalente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KnIQ8b7gTOt"
      },
      "source": [
        "## Tip of the day\n",
        "- You can adjust your preferences such, as **adding line numbers** to your code cells, **show indentation guide** and **changing the default indentation to 4**, in the settings->editor menu.\n",
        "\n",
        "- Displaying functions documentation: \n",
        " - You can quickly display a function's documentation by pressing **Alt+/** when standing on it with the cursor.\n",
        "\n",
        " - You can also open a small documentation window at the bottom of the screen by running a command for the format of **?{function}** in a new cell (and replacing **{function}** with your function's name.\n",
        "\n",
        "    Try opening a new cell, bellow this one by clicking on the **+code** button below the menu bar. Then type:\n",
        "```python\n",
        "?print\n",
        "```\n",
        "into it and run it.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLaeaYNlWxvx"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.display import Image\n",
        "import numpy.linalg as LA\n",
        "eps = 10**-12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hpVySaUXQBp"
      },
      "source": [
        "# Decision Tree\n",
        "Advantage of Decision Tree\n",
        "\n",
        "- Simple to understand and interpret. \n",
        "\n",
        "- Able to handle both numerical and categorical data. (today's lecture)\n",
        "\n",
        "- Requires little data preparation. \n",
        "\n",
        "- Uses a white box model. \n",
        "\n",
        "- Possible to validate a model using statistical tests.\n",
        "\n",
        "- Mirrors human decision making more closely than other approaches.\n",
        "\n",
        "\n",
        "Original ID3 algorithm accepts **categorical/discrete features** only and\n",
        "bears the overfitting issue. Also ID3 only works with classification. \n",
        "\n",
        "We will introduce **C4.5** algorithm, which is the successor to ID3. C4.5 improves from ID3 mainly in three-fold:\n",
        "\n",
        "- Accept continuous features by introducing thresholding node. \n",
        "\n",
        "- Solve overfitting problem by pruning strategy.\n",
        "\n",
        "- Can handle incomplete data points with missing feature values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22Y8n01FdzB3"
      },
      "source": [
        "## C4.5 Algorithm\n",
        "- One issue to use **information gain (IG)** is it favors to the feature has a large number of distinct values. \n",
        "\n",
        "- For example, suppose that one is building a decision tree for some data describing the customers of a business. \n",
        "\n",
        "  Information gain is often used to decide which of the features are the most relevant, so they can be tested near the root of the tree. One of the input features might be the customer's **credit card number**. This features has a high IG, because it uniquely identifies each customer, but we do not want to include it in the decision tree: deciding how to treat a customer based on their credit card number is unlikely to generalize to customers we haven't seen before. It is typical **overfitting**.\n",
        "\n",
        "- C4.5 Algorithm chooses the feature with **highest information gain ratio** from among the features whose **information gain is average or higher**. This biases the decision tree against considering features with a large number of distinct values, while not giving an unfair advantage to attributes with very low information value. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYlPpfcGTeCc"
      },
      "source": [
        "### Information gain ratio \n",
        "- Recall **Information gain (IG)** of set $\\mathcal{S}$ on some feature $F$ is\n",
        "$$ \\text{IG}(\\mathcal{S}; F)= H(\\mathcal{S})- H(\\mathcal{S}|F).$$\n",
        "\n",
        "- Conditional entropy of $\\mathcal{S}$ on $F$ is computed by\n",
        "$$ H(\\mathcal{S}|F) = \\sum_{f\\in F} P(F=f)H(\\mathcal{S}_f)=\\sum_{f\\in F} \\frac{|\\mathcal{S}_f|}{|\\mathcal{S}|}H(\\mathcal{S}_f)$$\n",
        "\n",
        "- Then entropy on feature $F$ is \n",
        "$$H(F) =-\\sum_{f\\in F}\\frac{|\\mathcal{S}_f|}{|\\mathcal{S}|} \\log_2\\left(\\frac{|\\mathcal{S}_f|}{|\\mathcal{S}|}\\right) $$\n",
        "which sometimes also called intrinsic value.\n",
        "\n",
        "- **Information gain ratio** is the ratio between the information gain and the intrinsic value: \n",
        "$$ \\text{IGR}(\\mathcal{S}; F) = \\text{IG}(\\mathcal{S}; F) /H(F)$$\n",
        "\n",
        "- The strategy is to choose the highest $\\text{IGR}$ among the features whose $\\text{IG}$ is average or higher. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvcPwRBmLxFG",
        "cellView": "form"
      },
      "source": [
        "#@title reuse functions defined before\n",
        "\n",
        "def entropy(df): #H(S)\n",
        "    target = df.keys()[-1] \n",
        "    entropy_data = 0\n",
        "    target_values = df[target].unique() #yes or no\n",
        "    for target_value in target_values:\n",
        "        fraction = df[target].value_counts()[target_value]/len(df[target])\n",
        "        entropy_data += -fraction*np.log2(fraction)\n",
        "    return entropy_data\n",
        "\n",
        "# define a function ent to calculate conditional entropy of each feature\n",
        "def entropy_feature(df,feature): #H(S|F)\n",
        "    target = df.keys()[-1] \n",
        "    target_values = df[target].unique()  #This gives all 'Yes' and 'No'\n",
        "    variables = df[feature].unique()    #This gives different features (f values)\n",
        "\n",
        "    entropy = 0\n",
        "    for variable in variables:\n",
        "        entropy_each_feature = 0\n",
        "        for target_variable in target_values:\n",
        "            num = len(df[feature][df[feature]==variable][df[target] ==target_variable]) #numerator\n",
        "            den = len(df[feature][df[feature]==variable])  #denominator\n",
        "            fraction = num/(den+eps)  #+eps can prevent runtime error of divide 0. \n",
        "            entropy_each_feature += -fraction*np.log2(fraction+eps) #This calculates entropy for one feature   H(S_f)\n",
        "        fraction2 = den/len(df) # P(F=f)\n",
        "        entropy += -fraction2*entropy_each_feature   #Sums up all the entropy, H(S|F)=\\sum P(F=f) H(S_f)\n",
        "\n",
        "    return(abs(entropy))\n",
        "\n",
        "# calculate Info gain of each feature \n",
        "def ig(df):\n",
        "    IG = []\n",
        "    for feature in df.keys()[:-1]:\n",
        "      IG.append(entropy(df)-entropy_feature(df,feature))\n",
        "    return IG  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "fHp3QFVA05pr",
        "outputId": "f65aa971-a808-40e7-ab36-817fb4bb7bf8"
      },
      "source": [
        "url = \"https://raw.githubusercontent.com/yexf308/MAT592/main/image/credithistory.csv\"\n",
        "c = pd.read_csv(url)\n",
        "c= c[['collateral','income','debt','credithistory','risk']]\n",
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>collateral</th>\n",
              "      <th>income</th>\n",
              "      <th>debt</th>\n",
              "      <th>credithistory</th>\n",
              "      <th>risk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>none</td>\n",
              "      <td>$0to$15K</td>\n",
              "      <td>high</td>\n",
              "      <td>bad</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>none</td>\n",
              "      <td>$15Kto$35K</td>\n",
              "      <td>high</td>\n",
              "      <td>unknown</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>none</td>\n",
              "      <td>$15Kto$35K</td>\n",
              "      <td>low</td>\n",
              "      <td>unknown</td>\n",
              "      <td>moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>none</td>\n",
              "      <td>$0to$15K</td>\n",
              "      <td>low</td>\n",
              "      <td>unknown</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>none</td>\n",
              "      <td>over$35K</td>\n",
              "      <td>low</td>\n",
              "      <td>unknown</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>adequate</td>\n",
              "      <td>over$35K</td>\n",
              "      <td>low</td>\n",
              "      <td>unknown</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>none</td>\n",
              "      <td>$0to$15K</td>\n",
              "      <td>low</td>\n",
              "      <td>bad</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>adequate</td>\n",
              "      <td>over$35K</td>\n",
              "      <td>low</td>\n",
              "      <td>bad</td>\n",
              "      <td>moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>none</td>\n",
              "      <td>over$35K</td>\n",
              "      <td>low</td>\n",
              "      <td>good</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>adequate</td>\n",
              "      <td>over$35K</td>\n",
              "      <td>high</td>\n",
              "      <td>good</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>none</td>\n",
              "      <td>$0to$15K</td>\n",
              "      <td>high</td>\n",
              "      <td>good</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>none</td>\n",
              "      <td>$15Kto$35K</td>\n",
              "      <td>high</td>\n",
              "      <td>good</td>\n",
              "      <td>moderate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>none</td>\n",
              "      <td>over$35K</td>\n",
              "      <td>high</td>\n",
              "      <td>good</td>\n",
              "      <td>low</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>none</td>\n",
              "      <td>$15Kto$35K</td>\n",
              "      <td>high</td>\n",
              "      <td>bad</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   collateral      income  debt credithistory      risk\n",
              "0        none    $0to$15K  high           bad      high\n",
              "1        none  $15Kto$35K  high       unknown      high\n",
              "2        none  $15Kto$35K   low       unknown  moderate\n",
              "3        none    $0to$15K   low       unknown      high\n",
              "4        none    over$35K   low       unknown       low\n",
              "5    adequate    over$35K   low       unknown       low\n",
              "6        none    $0to$15K   low           bad      high\n",
              "7    adequate    over$35K   low           bad  moderate\n",
              "8        none    over$35K   low          good       low\n",
              "9    adequate    over$35K  high          good       low\n",
              "10       none    $0to$15K  high          good      high\n",
              "11       none  $15Kto$35K  high          good  moderate\n",
              "12       none    over$35K  high          good       low\n",
              "13       none  $15Kto$35K  high           bad      high"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WJZqKpgifPZ"
      },
      "source": [
        "def get_subtable_no_node(df, node,variable):\n",
        "  tempdf = df[df[node] == variable].reset_index(drop=True)\n",
        "  return tempdf.drop(node, axis = 1)\n",
        "\n",
        "\n",
        "def ig_ratio(df):\n",
        "  IG = ig(df)\n",
        "  HF = []\n",
        "  features = df.keys()[:-1]\n",
        "  for feature in features:\n",
        "    entropy = 0\n",
        "    variables = df[feature].unique() \n",
        "    for variable in variables: \n",
        "      den = len(df[feature][df[feature]==variable])\n",
        "      fraction = den/len(df)\n",
        "      entropy += - fraction*np.log2(fraction + eps)\n",
        "\n",
        "    HF.append(entropy)\n",
        "\n",
        "  ratio = [IG[i]/HF[i] for i in range(len(IG))] \n",
        "  return ratio\n",
        "\n",
        "\n",
        "\n",
        "def C45(df):\n",
        "  \"\"\" \n",
        "   Find the feature with highest information gain ratio \n",
        "   from among the features whose information gain is average or higher.\n",
        "  \"\"\"\n",
        "  features = df.keys()[:-1]\n",
        "  IG = ig(df)\n",
        "  IG_ratio = ig(df)\n",
        "  IG_mean = np.mean(IG)\n",
        "  IG_above_ave_index = [i  for i in range(len(IG)) if IG[i]>=IG_mean ]\n",
        "  max_index = IG_above_ave_index[np.argmax( [IG_ratio[index] for index in IG_above_ave_index])]\n",
        "  return features[max_index]\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlapQ48ajavj"
      },
      "source": [
        "def buildTree(df,tree=None): \n",
        "    target = df.keys()[-1]   #To make the code generic, changing target variable class name\n",
        "    features = df.keys()[:-1]\n",
        "    if len(features) == 0:\n",
        "      target_values = df[target].unique()\n",
        "      target_count = [  df[target].value_counts()[target_value]  for target_value in target_values]\n",
        "      index = np.argmax(target_count)\n",
        "      tree = target_values[index]\n",
        "    else:\n",
        "      #Here we build our decision tree\n",
        "\n",
        "      #Get feature from C4.5\n",
        "      node = C45(df)\n",
        "      \n",
        "      #Get distinct value of that feature\n",
        "      variables = df[node].unique()\n",
        "      \n",
        "      #Create an empty dictionary to create tree    \n",
        "      if tree is None:                    \n",
        "          tree={}\n",
        "          tree[node] = {}\n",
        "      \n",
        "      #We make loop to construct a tree by calling this function recursively. \n",
        "      #In this we check if the subset is pure and stops if it is pure. \n",
        "\n",
        "      for variable in variables:\n",
        "          \n",
        "          subtable = get_subtable_no_node(df,node,variable)\n",
        "          clValue,counts = np.unique(subtable[target],return_counts=True)                        \n",
        "          \n",
        "          if len(counts)==1:#Checking purity of subset\n",
        "              tree[node][variable] = clValue[0]                                                    \n",
        "          else:        \n",
        "              tree[node][variable] = buildTree(subtable) #Calling the function recursively \n",
        "                    \n",
        "    return tree"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aayFbjV_hkXI",
        "outputId": "f4ffaaec-e9f8-4c10-8076-ed9757503a73"
      },
      "source": [
        "import pprint\n",
        "t=buildTree(c)\n",
        "pprint.pprint(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'income': {'$0to$15K': 'high',\n",
            "            '$15Kto$35K': {'credithistory': {'bad': 'high',\n",
            "                                             'good': 'moderate',\n",
            "                                             'unknown': {'debt': {'high': 'high',\n",
            "                                                                  'low': 'moderate'}}}},\n",
            "            'over$35K': {'credithistory': {'bad': 'moderate',\n",
            "                                           'good': 'low',\n",
            "                                           'unknown': 'low'}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCvY53zXPoB"
      },
      "source": [
        "## Classification and Regression Trees (CART)\n",
        "- It is a non-parametric decision tree learning technique that produces either classification or **regression** trees, depending on whether the target variable is categorical or numeric, respectively.\n",
        "\n",
        "- A couple issues in C4.5 is it is quite slow when the data is large since it  needs lots of logarithm calculations and it has non-binary tree. \n",
        "\n",
        "- CART uses **Gini impurity** as the metric and only uses binary tree. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsFNnKRBc6GB"
      },
      "source": [
        "### Gini impurity \n",
        "\n",
        "- Gini impurity is a measure of how often a randomly chosen element from the set would be incorrectly labeled if it was randomly labeled according to the distribution of labels in the subset. \n",
        "\n",
        "- Given a set of $\\mathcal{S}$ with $k$ target classes, the gini impurity is \n",
        "$$\\text{gini}(\\mathcal{S})=\\sum_{i=1}^k p_i (1-p_i) = 1-\\sum_{i=1}^k p_i^2. $$\n",
        "\n",
        "- Like entropy,  a node is pure (gini = 0) if all its samples belong to the same target class, while a node with many samples from many different target classes will have a Gini closer to 1. \n",
        "\n",
        "- The gini impurity is the first order Taylor expansion of entropy.\n",
        "Since $\\log_2(x)=\\frac{\\ln(x)}{\\ln(2)} \\approx \\frac{(-1+x+O(x))}{\\ln(2)}$\n",
        "\n",
        "$$ H(\\mathcal{S})=-\\sum_{i=1}^k p_i\\log_2(p_i) \\approx -\\frac{1}{\\ln(2)}\\sum_{i=1}^k p_i(-1+p_i)=\\frac{\\text{gini}(\\mathcal{S})}{\\ln(2)} $$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX0oJW1WXbZn"
      },
      "source": [
        "### Optimal splitting \n",
        "If the feature only has two discrete categories, then it is obvious to split into two branches. \n",
        "\n",
        "But if the feature has more than two discrete categories or even the feature is continuous variable. \n",
        "\n",
        "- The optimal splitting is that **the node is split so that the Gini impurity of the children (more specifically the average of the Gini of the children weighted by their size) is minimized.**\n",
        "\n",
        "- Mathematically, the set $\\mathcal{S}$ is splitted into two sets $\\mathcal{S}_1$ and $\\mathcal{S}_2$ based on some features and threshold $A$, i.e, $\\{\\mathcal{S_1}: \\mathbf{x}\\in A\\}$ and $\\{\\mathcal{S_2}: \\mathbf{x}\\notin A\\}$. \n",
        "we need to find the optimal feature and threshold $A$ such that \n",
        "$$\\text{gini}(\\mathcal{S},A) =  \\frac{|\\mathcal{S}_1|}{|\\mathcal{S}|}\\text{gini}(\\mathcal{S}_1) + \\frac{|\\mathcal{S}_2|}{|\\mathcal{S}|}\\text{gini}(\\mathcal{S}_2) $$\n",
        "is minimized. \n",
        "\n",
        "- **Algorithm**: \n",
        "   -  Iterate through the sorted feature values as possible thresholds. \n",
        "   - Keep track of the number of samples per class on the left and on the right.\n",
        "   -  Increment/decrement them by 1 after each threshold. From them we can easily compute Gini in constant time.. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00vuIcgSc6Xw"
      },
      "source": [
        "### For example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_p-y7QqDc1cu",
        "outputId": "20bf2b09-48bf-42de-e57c-d44cf1f2ff6b"
      },
      "source": [
        "X = '1.5,2.3,1.7,2.7,2.9'.split(',')\n",
        "y = '1,2,1,2,3'.split(',')\n",
        "dataset ={'X':X,'y':y}\n",
        "df = pd.DataFrame(dataset,columns=['X','y'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2.7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.9</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X  y\n",
              "0  1.5  1\n",
              "1  2.3  2\n",
              "2  1.7  1\n",
              "3  2.7  2\n",
              "4  2.9  3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSRs3ssEdbAk",
        "outputId": "eb3b99fc-9201-494b-96f9-dcc4f89b915d"
      },
      "source": [
        "def gini(df):\n",
        "    target = df.keys()[-1] \n",
        "    classes = df[target].unique()\n",
        "    m= len(df[target])\n",
        "    num_parent = [sum(df[target] == c) for c in classes]\n",
        "    best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
        "    return best_gini\n",
        "\n",
        "\n",
        "gini(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6399999999999999"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqfM2u_Teo9V"
      },
      "source": [
        "def best_split(df):\n",
        "  \"\"\"Find the best split for a node.\n",
        "    \"Best\" means that the average impurity of the two children, weighted by their\n",
        "     population, is the smallest possible. Additionally it must be less than the\n",
        "     impurity of the current node.\n",
        "     To find the best split, we loop through all the features, and consider all the\n",
        "     midpoints between adjacent training samples as possible thresholds. We compute\n",
        "     the Gini impurity of the split generated by that particular feature/threshold\n",
        "     pair, and return the pair with smallest impurity.\n",
        "        Returns:\n",
        "            best_idx: Index of the feature for best split, or None if no split is found.\n",
        "            best_thr: Threshold to use for the split, or None if no split is found.\n",
        "  \"\"\"\n",
        "  features   = df.keys()[:-1]\n",
        "  target     = df.keys()[-1] \n",
        "  target_values   = df[target].unique()\n",
        "  n_target_values = len(target_values)\n",
        "  m          = len(df[target])\n",
        "  num_parent = [sum(df[target] == c) for c in target_values]\n",
        "\n",
        "  best_gini = 1.0 - sum((n / m) ** 2 for n in num_parent)\n",
        "  best_feature, best_thr = None, None\n",
        "  # Loop through all features.\n",
        "\n",
        "  for feature in features:\n",
        "    # Sort data along selected feature.\n",
        "    thresholds, classes = zip(*sorted(zip(df[feature],df[target])))\n",
        "    num_left = [0]*n_target_values\n",
        "    num_right = num_parent.copy()\n",
        "    for i in range(1, m):  \n",
        "      c = classes[i - 1]\n",
        "      for idx, val in enumerate(target_values):\n",
        "        if c==val:\n",
        "          num_left[idx]  += 1\n",
        "          num_right[idx] -= 1\n",
        "\n",
        "       \n",
        "      gini_left = 1.0 - sum((num_left[idx] / i) ** 2 for idx in range(n_target_values) )\n",
        "      gini_right = 1.0 - sum((num_right[idx] / (m-i) ) ** 2 for idx in range(n_target_values) )\n",
        "      # The Gini impurity of a split is the weighted average of the Gini\n",
        "      # impurity of the children.\n",
        "      gini = (i * gini_left + (m - i) * gini_right) / m\n",
        "      \n",
        "      if thresholds[i] == thresholds[i - 1]:\n",
        "        continue\n",
        "\n",
        "      if gini < best_gini:\n",
        "        best_gini = gini\n",
        "        best_feature = feature\n",
        "        best_thr = (float(thresholds[i]) + float(thresholds[i - 1])) / 2 \n",
        "\n",
        "  return best_feature, best_thr         \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fewd7mPdPFSE",
        "outputId": "38968edd-8b96-4f3c-b7d8-3c3249b1e4c9"
      },
      "source": [
        "best_feature, best_thr = best_split(df)\n",
        "print(best_feature)\n",
        "print(best_thr)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X\n",
            "2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Q3JL9X5BRd"
      },
      "source": [
        "# Let's code this up on some test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-cDb1whY3h1l",
        "outputId": "66b02ead-5972-462d-ef42-d2a23bab9a81"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
        "                     columns= iris['feature_names'] + ['target'])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2     0.0\n",
              "1                4.9               3.0  ...               0.2     0.0\n",
              "2                4.7               3.2  ...               0.2     0.0\n",
              "3                4.6               3.1  ...               0.2     0.0\n",
              "4                5.0               3.6  ...               0.2     0.0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJwkQQVlBp0v"
      },
      "source": [
        "def get_subtable(df, node, best_thr):\n",
        "  return df[df[node] < best_thr].reset_index(drop=True), df[df[node] > best_thr].reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EE2nMIB70fN"
      },
      "source": [
        "def buildTree(df,tree=None): \n",
        "  target = df.keys()[-1]  \n",
        "  features = df.keys()[:-1]\n",
        "\n",
        "  best_feature, best_thr = best_split(df)\n",
        "  if best_feature is not None:\n",
        "    node                 = best_feature\n",
        "\n",
        "    #Create an empty dictionary to create tree    \n",
        "    if tree is None:                    \n",
        "      tree={}\n",
        "      tree[node] = {}\n",
        "\n",
        "    df_left, df_right = get_subtable(df, node, best_thr)\n",
        "    clValue_left, counts_left  = np.unique(df_left[target], return_counts=True)\n",
        "    clValue_right,counts_right = np.unique(df_right[target],return_counts=True)\n",
        "    left_variable  = '<' + str(best_thr)\n",
        "    right_variable = '>' + str(best_thr)\n",
        "\n",
        "    if len(counts_left)==1:\n",
        "      tree[node][left_variable] = clValue_left[0] \n",
        "    else:\n",
        "      tree[node][left_variable] = buildTree(df_left)  \n",
        "\n",
        "    if len(counts_right)==1:\n",
        "      tree[node][right_variable] = clValue_right[0] \n",
        "    else:\n",
        "      tree[node][right_variable] = buildTree(df_right) \n",
        "\n",
        "  return tree\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b8QWyVvHbY2",
        "outputId": "5cda6264-f553-4521-db61-ccb0ba826c2e"
      },
      "source": [
        "import pprint\n",
        "t=buildTree(df)\n",
        "pprint.pprint(t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'petal length (cm)': {'<2.45': 0.0,\n",
            "                       '>2.45': {'petal width (cm)': {'<1.75': {'petal length (cm)': {'<4.95': {'petal width (cm)': {'<1.65': 1.0,\n",
            "                                                                                                                     '>1.65': 2.0}},\n",
            "                                                                                      '>4.95': {'petal width (cm)': {'<1.55': 2.0,\n",
            "                                                                                                                     '>1.55': {'sepal length (cm)': {'<6.95': 1.0,\n",
            "                                                                                                                                                     '>6.95': 2.0}}}}}},\n",
            "                                                      '>1.75': {'petal length (cm)': {'<4.85': {'sepal length (cm)': {'<5.95': 1.0,\n",
            "                                                                                                                      '>5.95': 2.0}},\n",
            "                                                                                      '>4.85': 2.0}}}}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr0itxyoKke6"
      },
      "source": [
        "### We still need to write the prediction function, as well as pruning.\n",
        "\n",
        "The most comprehensive code is here: https://github.com/loginaway/DecisionTree. "
      ]
    }
  ]
}