{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN2vT8CQsAjn8QQgWTQap7W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yexf308/MachineLearning/blob/main/Module3/Convolutional_Neural_Network_Intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E6REan0RrLYn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$\\def\\m#1{\\mathbf{#1}}$\n",
        "$\\def\\mm#1{\\boldsymbol{#1}}$\n",
        "$\\def\\mb#1{\\mathbb{#1}}$\n",
        "$\\def\\c#1{\\mathcal{#1}}$\n",
        "$\\def\\mr#1{\\mathrm{#1}}$\n",
        "$\\newenvironment{rmat}{\\left[\\begin{array}{rrrrrrrrrrrrr}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\brm{\\begin{rmat}}$\n",
        "$\\newcommand\\erm{\\end{rmat}}$\n",
        "$\\newenvironment{cmat}{\\left[\\begin{array}{ccccccccc}}{\\end{array}\\right]}$\n",
        "$\\newcommand\\bcm{\\begin{cmat}}$\n",
        "$\\newcommand\\ecm{\\end{cmat}}$"
      ],
      "metadata": {
        "id": "Y2AG-0qq8FxN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Intro to Convolutional Neural Network\n",
        "Let's look at our MNIST example. We have 60000 training dataset with 10 labels and 10000 testing dataset. \n",
        "Here is the accuracy of MNIST example. \n",
        "\n",
        "| classifier        | Test Error                                                      | \n",
        "|---------|-------------------------------------------------------|\n",
        "|Linear classifier     |12%                          |\n",
        "|SVM, Gaussian kernel   |1.4%                                      |\n",
        "|SVM, degree 4 polynomial  |1.1%                                   |\n",
        "|Best SVM result      |0.56%                                                    |\n",
        "|2-layer NN      |~3%            |\n",
        "|3-layer NN      |~2.5%                             |\n",
        "|CNN, LeNet-5 (1998)      |0.85%                          |\n",
        "|Larger CNN (2011, 2012)   |~0.3%                |\n",
        "\n",
        "\n",
        "MNIST digits are done! \n",
        "\n",
        "### ImageNet Classification Challenge\n",
        "ImageNet dataset has ~1.2M color images of size $256\\times256$ for training and 100K for testing with ~1000 object classes.\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/imagenet1.png?raw=true\" width=\"800\" />\n",
        "\n",
        "\n",
        "**Models are Getting Deeper and Larger**.\n",
        "Computations of training large scale networks are made parallelizable by using GPUs, an essential ingredient of the deep learning revolution. \n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/imagenet2.png?raw=true\" width=\"800\" />\n",
        "\n",
        "**Why?**\n",
        "Fully connected networks doesn’t work well for computer vision\n",
        "applications! Because it has too many parameters and very hard to train. So it has poor performance. \n",
        "\n",
        "**Structure of VGG**\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/vgg.png?raw=true\" width=\"500\" />\n",
        "\n",
        "\n",
        "If the first layer is fully connected, \n",
        "- Input: $224\\times 224\\times 3$\n",
        "\n",
        "- Output: $224\\times 224\\times 64$.\n",
        "\n",
        "- Number of parameters: 483 Billions!\n",
        "\n",
        "\n",
        "Two important layers we will discuss later:\n",
        "- Convolution: **Local connectivity** and **parameter sharing**. \n",
        "- Pooling: reduce the size of representation, down-sampling.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gs_pobWErny8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convolutional layers\n",
        "- It is a **linear** layer!\n",
        "\n",
        "- It take image or features output from hidden layers as input in its original shape without vectorization. i.e., The input dimension is $224\\times 224\\times 3$. \n",
        "\n",
        "- It can better capture the spatial information in an image. \n",
        "\n",
        "- Trainable weights are typically 3-D or 4-D tensors, called **filters**. \n",
        "\n",
        "- **Weights sharing** and **local(sparse) connectivity** in contrast to full connectivity in dense layers. \n",
        "\n",
        "- Much more compact in terms of model size (i.e., less parameters)\n",
        "\n",
        "\n",
        "### Local connectivity\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/cnn1.png?raw=true\" width=\"500\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/cnn2.png?raw=true\" width=\"500\" />\n",
        "\n",
        "Each hidden unit is connected only to a sub-region of input. It is connected to all channels (R, G, B). \n",
        "\n",
        "### Parameter Sharing\n",
        "Making one reasonable **assumption**: \n",
        "If one feature is useful to compute at some spatial position $(x, y)$, then it\n",
        "should also be useful to compute at a different position $(x_2, y_2)$\n",
        "\n",
        "### Convolution Operator\n",
        "The convolution of an image $\\m{x}$ with a kernel $\\m{k}$ is computed as\n",
        "\\begin{align}\n",
        "(\\m{x}\\ast \\m{k})_{ij} = \\sum_{pq} \\m{x}_{i+p, j+q}\\m{k}_{p,q}\n",
        "\\end{align}\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/conv.png?raw=true\" width=\"400\" />\n",
        "\n",
        "\n",
        "$$ $$\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/conv1.png?raw=true\" width=\"400\" />\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/conv2.png?raw=true\" width=\"400\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/conv3.png?raw=true\" width=\"400\" />\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/conv4.png?raw=true\" width=\"400\" />\n",
        "\n",
        "\n",
        "## Remarks for 2-D convolutions\n",
        "2-D convolution works for matrix input:\n",
        "\n",
        "- One convolution filter of (kernel) size $2\\times 2$ (with just 4 weights)\n",
        "transforms $3\\times 3$ input into $2\\times 2 $ output. \n",
        "\n",
        "- In contrast, a dense layer would have $4\\times 9$ = 36 weights!\n",
        "\n",
        "- Could have bias term. \n",
        "\n",
        "- Could have multiple  filters of (kernel) size $2\\times 2$ (say, 4 filters with $4\\times 4$\n",
        "weights), then the output is a $4 \\times2 \\times 2$ tensor (each  filter gives a $2\\times 2$\n",
        "slice of the 3-D tensor).\n",
        "\n",
        "- Typical choices of kernel size are $3\\times 3, 5\\times 5$ and $7\\times 7$. \n",
        "\n",
        "### Example:\n",
        "- Input Size: $3\\times d\\times d$.\n",
        "\n",
        "- Filter Size: $3\\times 3\\times 3$ with kernel size $3\\times 3$, stride=1. \n",
        "\n",
        "- Output Size: $(d-2)\\times (d-2)$. Convolutions Reduce Image Dimensions! If we have multiple layers of convolutions, then the dimension will be smaller and smaller. This is a problem. \n",
        "\n",
        " \n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/cnn3.png?raw=true\" width=\"600\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/cnn4.png?raw=true\" width=\"600\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/cnn5.png?raw=true\" width=\"600\" />\n",
        "\n",
        "\n",
        "\n",
        "### Zero padding\n",
        "\n",
        "Use zero padding to allow going over the boundary\n",
        "Easier to control the size of output layer. So the dimension of input and output will be the same. Both are $d\\times d$. \n",
        "\n",
        "\n",
        "\n",
        "![padding](https://github.com/yexf308/MAT592/blob/main/image/padding.gif?raw=true \"padding\")\n",
        "\n",
        "\n",
        "## 3-D inputs to convolutional layer\n",
        "(Without zero padding)\n",
        "Convolve $d_{in} \\times w_{in}\\times h_{in}$ input features with $d_{out}$  filters of size $d_{in}\\times d_{ker}\\times d_{ker}$\n",
        "and stride = 1, then size of output features is\n",
        "$d_{out} \\times (w_{in} - d_{ker} + 1) \\times (h_{in} - d_{ker} + 1)$\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/cnn6.png?raw=true\" width=\"400\" />\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "WtfpqYdD189y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pooling layer\n",
        "- It’s common to insert a pooling layer in-between successive\n",
        "convolutional layers. \n",
        "\n",
        "- Pooling layers reduce the spatial size of features to reduce the amount of parameters. \n",
        "\n",
        "- It operates on each feature slice independently.\n",
        "\n",
        "### Max Pooling\n",
        "$2\\times 2$ max pooling (with stride 2) is commonly used. By pooling, we gain robustness to the exact spatial location of features. \n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/pooling1.png?raw=true\" width=\"800\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/pooling2.png?raw=true\" width=\"400\" />"
      ],
      "metadata": {
        "id": "vhwNs5O-X9zU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Examples on CNN\n",
        "\n",
        "### LeNet\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/LeNet.png?raw=true\" width=\"600\" />\n",
        "\n",
        "Pad images with zeros and increase the size to $32\\times 32$.\n",
        "- Input: 32 × 32 images (MNIST)\n",
        "\n",
        "- Convolution 1: 6 5 × 5 filters, stride 1 (followed by sigmoid\n",
        "activation layer)\n",
        "   - Output: 6 28 × 28 maps \n",
        "\n",
        "- Pooling 1: 2 × 2 max pooling, stride 2\n",
        "   - Output: 6 14 × 14 maps\n",
        "\n",
        "- Convolution 2: 16 5 × 5 filters, stride 1 (followed by sigmoid\n",
        "activation))\n",
        "   - Output: 16 10 × 10 maps\n",
        "\n",
        "- Pooling 2: 2 × 2 max pooling with stride 2  \n",
        "   - Output: 16 5 × 5 maps (total 400 values)\n",
        "\n",
        "- 3 fully connected layers:  120 ⇒ 84 (followed by sigmoid activation)) ⇒ 10 neurons (followed by softmax output layer)        \n",
        "\n",
        "In total 61,706 trainable parameters including weights and biases\n",
        "easily > 99% test accuracy for MNIST. \n",
        "\n",
        "ReLU activation is used nowadays for better accuracy.\n",
        "\n",
        "### AlexNet\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/AlexNet.png?raw=true\" width=\"600\" />\n",
        "\n",
        "AlexNet: \n",
        "- 8 layers in total, about 60 million\n",
        "parameters and 650,000 neurons.\n",
        "- Trained on ImageNet dataset. \n",
        "\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/compare_cnn.png?raw=true\" width=\"600\" />\n",
        "\n",
        "### Learned kernel in AlexNet\n",
        "\n",
        "- The receptive field of a neuron is the input region that can affect the neuron’s output. \n",
        "\n",
        "- The receptive field for a first layer neuron is its neighbors (depending on kernel size) ⇒ capturing very local patterns. \n",
        " \n",
        "- For higher layer neurons, the receptive field can be much larger ⇒\n",
        "capturing global patterns. \n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/AlexNet2.png?raw=true\" width=\"400\" />\n",
        "\n",
        "<img src=\"https://github.com/yexf308/MAT592/blob/main/image/AlexNet3.png?raw=true\" width=\"600\" />\n"
      ],
      "metadata": {
        "id": "99SYm87V8U1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training on CNN\n",
        "\n",
        "- Apply SGD to minimize in-sample training error\n",
        "- Backpropagation can be extended to convolutional layer and pooling\n",
        "layer to compute gradient!\n",
        "- Millions of parameters ⇒ easy to overfit. More to be discussed! "
      ],
      "metadata": {
        "id": "gRaYG73kGDdm"
      }
    }
  ]
}